[2025-07-06T00:00:1277Z] (neutral) ? 1. VOSK Mic Listener (vosk-mic.js) [#system #seg-1278]
[2025-07-06T00:00:1277Z] (neutral)  [#this script #seg-1278]
[2025-07-06T00:00:1277Z] (neutral) * UsesÊmicÊto capture audio [#system #seg-1278]
[2025-07-06T00:00:1277Z] (neutral) * Transcribes it locally withÊvosk [#system #seg-1278]
[2025-07-06T00:00:1277Z] (neutral) * Emits phrases to console (or pipes into Aegis later) [#system #seg-1278]
[2025-07-06T00:00:1277Z] (neutral) ??Êscripts/vosk-mic.js [#system #seg-1278]
[2025-07-06T00:00:1277Z] (neutral) ? 1. VOSK Mic Listener (vosk-mic.js) [#system #seg-1278]
[2025-07-06T00:00:1277Z] (neutral)  [#this script #seg-1278]
[2025-07-06T00:00:1277Z] (neutral) * UsesÊmicÊto capture audio [#system #seg-1278]
[2025-07-06T00:00:1277Z] (neutral) * Transcribes it locally withÊvosk [#system #seg-1278]
[2025-07-06T00:00:1277Z] (neutral) * Emits phrases to console (or pipes into Aegis later) [#system #seg-1278]
[2025-07-06T00:00:1277Z] (neutral) ??Êscripts/vosk-mic.js [#system #seg-1278]
[2025-07-06T00:00:1277Z] (neutral) String(SAMPLE_RATE), channels: '1', debug: false, exitOnSilence: 6 }); const stream = micInstance.getAudioStream(); stream.on('data', (data) => { if (recognizer.acceptWaveform(data)) { const result = JSON.parse(recognizer.result()); if (result.text) { console.log(`??? You said: ${result.text}`); // TODO: Pipe this to Aegis input or SpeechBrain verification } } }); stream.on('error', (err) => { console.error('? Mic error:', err); }); stream.on('startComplete', () => { console.log('?? Listening for your voiceÉ'); }); micInstance.start(); [#// scripts/vosk-mic.js import { model, kaldirecognizer } from 'vosk'; import mic from 'mic'; import fs from 'fs'; const model_path = 'models/vosk-model-small-en-us-0.15'; const sample_rate = 16000; if (!fs.existssync(model_path)) { console.error(`? vosk model not found at ${model_path}`); process.exit(1); } const model = new model(model_path); const recognizer = new kaldirecognizer(model, sample_rate); const micinstance = mic({ rate #seg-1278]
[2025-07-06T00:00:1277Z] (neutral) ? 1. VOSK Mic Listener (vosk-mic.js) [#system #seg-1278]
[2025-07-06T00:00:1277Z] (neutral)  [#this script #seg-1278]
[2025-07-06T00:00:1277Z] (neutral) * UsesÊmicÊto capture audio [#system #seg-1278]
[2025-07-06T00:00:1277Z] (neutral) * Transcribes it locally withÊvosk [#system #seg-1278]
[2025-07-06T00:00:1277Z] (neutral) * Emits phrases to console (or pipes into Aegis later) [#system #seg-1278]
[2025-07-06T00:00:1277Z] (neutral) ??Êscripts/vosk-mic.js [#system #seg-1278]
[2025-07-06T00:00:1277Z] (neutral) String(SAMPLE_RATE), channels: '1', debug: false, exitOnSilence: 6 }); const stream = micInstance.getAudioStream(); stream.on('data', (data) => { if (recognizer.acceptWaveform(data)) { const result = JSON.parse(recognizer.result()); if (result.text) { console.log(`??? You said: ${result.text}`); // TODO: Pipe this to Aegis input or SpeechBrain verification } } }); stream.on('error', (err) => { console.error('? Mic error:', err); }); stream.on('startComplete', () => { console.log('?? Listening for your voiceÉ'); }); micInstance.start(); [#// scripts/vosk-mic.js import { model, kaldirecognizer } from 'vosk'; import mic from 'mic'; import fs from 'fs'; const model_path = 'models/vosk-model-small-en-us-0.15'; const sample_rate = 16000; if (!fs.existssync(model_path)) { console.error(`? vosk model not found at ${model_path}`); process.exit(1); } const model = new model(model_path); const recognizer = new kaldirecognizer(model, sample_rate); const micinstance = mic({ rate #seg-1278]
