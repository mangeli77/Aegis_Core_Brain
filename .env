# ================================
# Aegis Integration Environment
# ================================

# ----- Whisper (optional local STT) -----
WHISPER_DEVICE_INDEX=5
WHISPER_MODEL_PATH=/Users/Aegis/whisper.cpp/models/ggml-base.en.bin
VOICE_INPUT_PATH=voice/input.wav

# ----- OpenAI (cognition) -----
OPENAI_API_KEY=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
# If you ever proxy OpenAI, set this; otherwise you can omit it.
# OPENAI_API_BASE=https://api.openai.com/v1

# ----- Ollama (local LLM) -----
OLLAMA_MODEL=llama2:latest
OLLAMA_HOST=http://127.0.0.1:11434

# ----- ElevenLabs (voice TTS) -----
ELEVENLABS_API_KEY=sk_0047b5ea245db0f0e7dfd0b6647df5dd0803c186efd00af0
ELEVENLABS_VOICE_ID=FG350wLfM2HDwTst4Q7I
ENABLE_ELEVENLABS_TTS=true

# ----- Local TTS toggle (future) -----
ENABLE_LOCAL_TTS=false

# ----- Output path for generated speech -----
VOICE_OUTPUT_PATH=voice/elevenlabs_output.mp3